{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3818b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "import string\n",
    "import random\n",
    "import pickle\n",
    "import numpy\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e60d0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatdata(formatted_sentences,formatted_labels,file_name):\n",
    "\t#file=open(\"en-ud-dev.conllu\",\"r\")\n",
    "\tfile=open(file_name, 'r', encoding='ascii', errors='backslashreplace')\n",
    "\t#file=open(file_name,\"rb\")\n",
    "\tprint(\"Reading data...\")\n",
    "\t#quit()\n",
    "\ttext=file.read().splitlines()\n",
    "\ttokens=[]\n",
    "\tlabels=[]\n",
    "\tfor line in text:\n",
    "\t\tline=line.split('\\t')\n",
    "\t\tif len(line)==3:\n",
    "\t\t\ttokens.append(line[0])\n",
    "\t\t\tif line[1]==\"PUNCT\":\n",
    "\t\t\t\tlabels.append(line[0]+\"P\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tlabels.append(line[2])\t\n",
    "\t\telse:\n",
    "\t\t\tformatted_sentences.append(tokens)\n",
    "\t\t\tformatted_labels.append(labels)\n",
    "\t\t\ttokens=[]\n",
    "\t\t\tlabels=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "661d5588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatdict(sentence,index,pos):\t#pos==\"\" <-> featuresofword  else, relative pos (str) is pos\n",
    "\tword=sentence[index]\n",
    "\twordlow=word.lower()\n",
    "\tdict2={\n",
    "\t\t\"wrd\"+pos:wordlow,\t\t\t\t\t\t\t\t# the token itself\n",
    "\t\t\"cap\"+pos:word[0].isupper(),\t\t\t\t\t# starts with capital?\n",
    "\t\t\"allcap\"+pos:word.isupper(),\t\t\t\t\t# is all capitals?\n",
    "\t\t\"caps_inside\"+pos:word==wordlow,\t\t\t\t# has capitals inside?\n",
    "\t\t\"nums?\"+pos:any(i.isdigit() for i in word),\t\t# has digits?\n",
    "        \"punct\"+pos:any(i in string.punctuation for i in word),# has punctuation?\n",
    "\t}\t\n",
    "\t\n",
    "\treturn dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9def12fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(sentence,index):\n",
    "\tfeatures=creatdict(sentence,index,\"\")\n",
    "\n",
    "\treturn features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b18b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatsets(file_name):\t\n",
    "\tsentences=[]\n",
    "\tlabels=[] \t#y_train (will be)\n",
    "\tformatdata(sentences,labels,file_name)\t\n",
    "\tlimit=int(len(sentences)/5)##############**********CHANGE these. these just limit the size of training set for faster trials. #####################\n",
    "\tsentences=sentences[:limit]##############\n",
    "\tlabels=labels[:limit]####################\n",
    "\t\n",
    "\t#print(len(sentences),len(labels))\t\t\t\n",
    "\t#print(formatted_sentences)\n",
    "\t#print(formatted_labels)\n",
    "\tprint(\"Feature extraction...\")\n",
    "\tfeatures=[]\t\t#X_train\n",
    "\tfor i in range(0,len(sentences)):\n",
    "\t\tfeatures.append([])\n",
    "\t\tfor j in range(0,len(sentences[i])):\n",
    "\t\t\tfeatures[-1].append(feature_extractor(sentences[i],j))\n",
    "\t\t\t\n",
    "\tdel sentences[:]\n",
    "\tdel sentences\n",
    "\n",
    "\t\n",
    "\tdelimit=int((len(labels)*8)/10)\n",
    "\ttest_data=[features[delimit:],labels[delimit:]]\n",
    "\tfeatures=features[:delimit]\n",
    "\tlabels=labels[:delimit]\n",
    "\t\n",
    "\ttraining_data=[features,labels]\n",
    "\n",
    "\t\n",
    "\twith open('pos_crf_train.data', 'wb') as file:\n",
    "\t\tpickle.dump(training_data, file)\n",
    "\tfile.close()\n",
    "\n",
    "\n",
    "\twith open('pos_crf_test.data', 'wb') as file:\n",
    "\t\tpickle.dump(test_data, file)\n",
    "\tfile.close()\n",
    "\t\t\n",
    "\treturn training_data, test_data\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d2c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(training_data):\t\t\n",
    "\tprint(\"Training...\")\n",
    "\tfeatures=training_data[0]\n",
    "\tlabels=training_data[1]\t\n",
    "\tclassifier.fit(features,labels)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d054ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_data):\n",
    "\tprint(\"Testing...\")\n",
    "\n",
    "\ty_true=test_data[1]  #labels\n",
    "\ty_pred=classifier.predict(test_data[0])\n",
    "\t\n",
    "\t#print(y_pred[0])\n",
    "\t\n",
    "\tprecision=sklearn_crfsuite.metrics.flat_precision_score(y_true, y_pred,average='micro')\n",
    "\trecall=sklearn_crfsuite.metrics.flat_recall_score(y_true, y_pred,average='micro')\n",
    "\tf1=2*(precision*recall)/(precision+recall)\n",
    "\taccuracy=sklearn_crfsuite.metrics.flat_accuracy_score(y_true, y_pred)\n",
    "\n",
    "\tprint(\"accuracy:\",accuracy)\n",
    "\tprint(\"f1:\",f1)\n",
    "\tprint(\"precision:\",f1)\n",
    "\tprint(\"recall:\",recall)\n",
    "\t\n",
    "\t\n",
    "\timport plotly\n",
    "\timport plotly.graph_objects as go\n",
    "\n",
    "\tflat_y_true=[]\n",
    "\tflat_y_pred=[]\n",
    "\t\n",
    "\tfor x in y_true:\n",
    "\t\tfor y in x:\n",
    "\t\t\tflat_y_true.append(y)\n",
    "\t\n",
    "\tfor x in y_pred:\n",
    "\t\tfor y in x:\n",
    "\t\t\tflat_y_pred.append(y)\t\t\n",
    "\t\n",
    "\tend_p=[\"RP\",\"NFP\",\"VBP\",\"NNP\",\"PRP\",\"WP\"]\n",
    "\tfor i in range(0,len(flat_y_true)):\n",
    "\t\tif flat_y_true[i][-1]==\"P\" and flat_y_true[i][-1] not in end_p: \n",
    "\t\t\tflat_y_true[i]=\"PUNCT\"\n",
    "\t\tif flat_y_pred[i][-1]==\"P\" and flat_y_pred[i][-1] not in end_p: \n",
    "\t\t\tflat_y_pred[i]=\"PUNCT\"\n",
    "\t\t\n",
    "\t#print(type(flat_y_true))\n",
    "\t#print(flat_y_true[0],flat_y_true[-1])\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e677eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(filename):\t#filename shall end with .pickle and type(filename)=string\n",
    "\tprint(\"Saving classifier.\")\n",
    "\twith open(filename, \"wb\") as f:\n",
    "\t\tpickle.dump(classifier, f)\n",
    "\treturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6f80775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filename):\t#filename shall end with .pickle and type(filename)=string\n",
    "\tprint(\"Loading classifier...\")\n",
    "\twith open(filename, \"rb\") as f:\n",
    "\t\tclassifier=pickle.load(f)\n",
    "\t\treturn classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c124dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(sentence):\n",
    "\t#takes a single sentence as a list\n",
    "\tclassifier=load(\"pos_crf.pickle\")\n",
    "\tt_features=[]\n",
    "\tfor j in range(0,len(sentence)):\t\n",
    "\t\tt_features.append(feature_extractor(sentence,j))\n",
    "\t\t\n",
    "\t#print(sentence)\n",
    "\t#print(len(t_features))\t\n",
    "\t\n",
    "\tret=classifier.predict([t_features])[0]\n",
    "\tend_p=[\"RP\",\"NFP\",\"VBP\",\"NNP\",\"PRP\",\"WP\"]\n",
    "\tfor i in range(0,len(ret)):\n",
    "\t\tif ret[i][-1]==\"P\" and ret[i][-1] not in end_p: \n",
    "\t\t\tret[i]=\"PUNCT\"\n",
    "\n",
    "\treturn ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b090b08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Feature extraction...\n",
      "Training...\n",
      "Saving classifier.\n",
      "Loading classifier...\n",
      "Testing...\n",
      "accuracy: 0.8957098011859086\n",
      "f1: 0.8957098011859086\n",
      "precision: 0.8957098011859086\n",
      "recall: 0.8957098011859086\n",
      "Loading classifier...\n",
      "['DT', 'NN', 'VBD', 'IN', 'DT', 'NNS', 'RB', 'IN', 'CD', 'VBD', 'CD', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "\tclassifier=sklearn_crfsuite.CRF(c1=0.2, c2=0.2, max_iterations=1000)\n",
    "\ttraining_data, test_data=creatsets(\"en-ud-train.conllu\")\n",
    "\t\n",
    "\t\n",
    "\twith open('pos_crf_train.data', 'rb') as file:\n",
    "\t\ttraining_data=pickle.load(file)\n",
    "\tfile.close()\n",
    "\t\n",
    "\t\n",
    "\ttrain(training_data)\n",
    "\t#quit()\n",
    "\tsave(\"pos_crf.pickle\")\n",
    "\t\n",
    "\t\n",
    "\twith open('pos_crf_test.data', 'rb') as file:\n",
    "\t\ttest_data=pickle.load(file)\n",
    "\tfile.close()\n",
    "\t\n",
    "\tclassifier=load(\"pos_crf.pickle\")\n",
    "\ttest(test_data)\n",
    "\t\n",
    "\ts=['The',\n",
    "\t'guitarist',\n",
    "\t'died',\n",
    "\t'of',\n",
    "\t'a',\n",
    "\t'drugs',\n",
    "\t'overdose',\n",
    "\t'in',\n",
    "\t'1970',\n",
    "\t'aged',\n",
    "\t'27',\n",
    "\t'.']\n",
    "\t\n",
    "\tprint(tag(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9df04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
